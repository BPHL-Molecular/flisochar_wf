#!/usr/bin/env python3
# pgap_summary_v01.py
# Author : Tassy Joseph-S. Bazile, Bioinformatian ApHL Bioinformatics Fellow 2021-2023  
#sys.path.append('/usr/sammy/') to get append the path of a module
import os
import pandas as pd
import numpy as np
import re
import xlsxwriter
from Bio import SeqIO
from collections import Counter
import argparse

parser = argparse.ArgumentParser(prog = 'pgap_summary_v01.py [Options]')
parser.add_argument('--pgapres', type=str, help =' provide the path to gpagp output directory ', required=True)
args = parser.parse_args()
pg_dir = args.pgapres

"""
Business Logic:
The module creates the summary report of the pgap annotation.

Usage:
python pgap_summary_v01.py --pgapres

"""
def pgap_report(s,path_to_gbk):

# Lists to collect data for all the records
    genes_list = []
    cds_list = []
    tRna_list = []
    rRna_list = []
    tmRna_list = []
    ncRna_list = []
    features_set = set()
    feature_tot = []

    # SeqIO.parse(*.gbk) used for a mutiple-record file; SeqIO.read(*.gbk) for a single record file
    for seq_record in SeqIO.parse(path_to_gbk, "genbank"):
        
        """
        Everything below is for each single record
        From record, getting features
        feature_Rec = seq_record.features
        From features, getting types
        """
        feature_Rec = seq_record.features
        all_feature_types = [feature.type for feature in feature_Rec]
        
        feature_type = set(all_feature_types)
        
        feature_counts = Counter(all_feature_types) # a dictionary mapping feature and number "for each record"
        
        # Looking at the features
        feature_counts.keys()
        # feature_counts.keys(): dict_keys(['source', 'gene', 'CDS', 'tRNA']) ... for each record 
        #Removing source       
        del feature_counts['source']
        # List of Features
        features_keylist = list(feature_counts.keys()) # list of features per record
        [features_set.add(it) for it in features_keylist] # features for all records

        # Adding the dictionary feature_count to dataframe
        df_features = pd.DataFrame(list(feature_counts.items())) # creating df from dictionary
        df_featuresT =  df_features.transpose()
        header_row = df_featuresT.iloc[0] # converting row into column header
        df_features2 = pd.DataFrame(df_featuresT.values[1:], columns =  header_row)  
        df_features2.insert(0,"SampleID", s, True)  # adding at column the position zero
        return df_features2

# parsing df to csv and txt files   
def report_csv(df_features2):
    df_features2.to_csv('pgap_annotation_report.txt', sep=' ', index=True, header=True)
    df_features2.to_csv('pgap_annotation_report.csv', sep=' ', index=True, header=True)
    with pd.ExcelWriter('pgap_annotation_report.xlsx', engine='xlsxwriter') as writer: # writer is to add more than one sheet in the workbook
        df_features2.to_excel(writer, sheet_name='Annotation_Report', startrow=1)
        #writer.save()
    return
                       
def main():
    pgap_resPath = pg_dir
    sampledir_list = os.listdir(pg_dir)
    sampledir_list.sort()
    sampId_list = [samp.split('_')[0] for samp in sampledir_list]
    df_list = []
    for s in sampId_list:  
        saved_path = pgap_resPath +'/'+ s + '_results/'
        rep_file = 'annot.gbk'
        path_to_gbk = os.path.join(saved_path, rep_file)
        feature_df = pgap_report(s, path_to_gbk)
        
        df_list.append(feature_df)
        feature_dfn = pd.concat(df_list)
        feature_dfn.index = np.arange(1, len(feature_dfn) + 1)
    print(feature_dfn)
    report_csv(feature_dfn)
if __name__ == "__main__":
    main()

